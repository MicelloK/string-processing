{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metryki w przestrzeni napisów"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadanie dotyczy różnych metryk w przestrzeni napisów.\n",
    "\n",
    "1. Zaimplementuj przynajmniej 3 \"metryki\" spośród wymienionych: cosinusowa, LCS, DICE, euklidesowa, Levenshteina.\n",
    "2. Zaimplementuj przynajmniej 1 sposoby oceny jakości klasteryzacji (np. indeks Daviesa-Bouldina).\n",
    "3. Stwórz stoplistę najczęściej występujących słów i zastosuj ją jako pre-processing dla nazw. Algorytmy klasteryzacji powinny działać na dwóch wariantach: z pre-processingiem i bez pre-processingu.\n",
    "4. Wykonaj klasteryzację zawartości załączonego pliku (lines.txt) przy użyciu  metryk zaimplementowanych w pkt. 1. Każda linia to adres pocztowy firmy, różne sposoby zapisu tego samego adresu powinny się znaleźć w jednym klastrze.\n",
    "5. Porównaj jakość wyników sposobami zaimplementowanymi w pkt. 2.\n",
    "6. Czy masz jakiś pomysł na poprawę jakości klasteryzacji w tym zadaniu?\n",
    "\n",
    "Sprawozdanie powinno zawierać porównanie wyników wszystkich metryk z użyciem stoplisty i bez.\n",
    "\n",
    "Można jako wzorcową klasteryzację użyć pliku clusters.txt.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs_metric(x, y):\n",
    "    \"\"\"\n",
    "    Calculates the Longest Common Subsequence (LCS) metric between two strings.\n",
    "    \"\"\"\n",
    "    if len(x) == 0 or len(y) == 0:\n",
    "        return 1\n",
    "    tab = [[None for j in range(len(y)+1)] for i in range(len(x)+1)]\n",
    "    max_lcs = 0\n",
    "    for i in range(len(x)+1):\n",
    "        for j in range(len(y)+1):\n",
    "            if i == 0 or j == 0:\n",
    "                tab[i][j] = 0\n",
    "            else:\n",
    "                if x[i-1] == y[j-1]:\n",
    "                    tab[i][j] = 1 + tab[i-1][j-1]\n",
    "                else:\n",
    "                    tab[i][j] = 0\n",
    "            if tab[i][j] > max_lcs:\n",
    "                max_lcs = tab[i][j]\n",
    "    return 1 - max_lcs/max(len(x), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngram_vec(x, N=2):\n",
    "    vec = {}\n",
    "    for i in range(len(x)-N+1):\n",
    "        if x[i:i+N] in vec:\n",
    "            vec[x[i:i+N]] += 1\n",
    "        else:\n",
    "            vec[x[i:i+N]] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_metric(a, b):\n",
    "    \"\"\"\n",
    "    Calculates the Cosine metric between two strings.\n",
    "    \"\"\"\n",
    "    if len(a) == 0 or len(b) == 0:\n",
    "        return 1\n",
    "    a = set(make_ngram_vec(a).keys())\n",
    "    b = set(make_ngram_vec(b).keys())\n",
    "    return 1 - len(a.intersection(b)) / np.sqrt(len(a)*len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_metric(a, b):\n",
    "    \"\"\"\n",
    "    Calculates the Euclidean metric between two strings.\n",
    "    \"\"\"\n",
    "    a = make_ngram_vec(a)\n",
    "    b = make_ngram_vec(b)\n",
    "    keys = set(a.keys()).union(set(b.keys()))\n",
    "    return np.sqrt(sum((a.get(k, 0) - b.get(k, 0))**2 for k in keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_metric(a, b):\n",
    "    \"\"\"\n",
    "    Calculates the Dice metric between two strings.\n",
    "    \"\"\"\n",
    "    a = set(make_ngram_vec(a).keys())\n",
    "    b = set(make_ngram_vec(b).keys())\n",
    "    if len(a) == 0 or len(b) == 0:\n",
    "        return 1\n",
    "\n",
    "    return 1 - (2 * len(a.intersection(b))) / (len(a) + len(b))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(cluster, metric):\n",
    "    \"\"\"\n",
    "    Calculates the centroids of the clusters.\n",
    "    \"\"\"\n",
    "    dists = [0 for i in cluster]\n",
    "    for i in range(len(cluster)):\n",
    "        for j in range(i):\n",
    "            dist = metric(cluster[i], cluster[j])\n",
    "            dists[i] += dist\n",
    "            dists[j] += dist      \n",
    "    min_dist = 10**100 # inf\n",
    "    res = -1\n",
    "    for i in range(len(dists)):\n",
    "        if dists[i] < min_dist:\n",
    "            min_dist = dists[i]\n",
    "            res = i\n",
    "    return cluster[res] \n",
    "\n",
    "\n",
    "def avg_dist(cluster, metric):\n",
    "    if len(cluster) < 2:\n",
    "        return 0\n",
    "    if len(cluster) == 2:\n",
    "        return metric(cluster[0], cluster[1])\n",
    "    \n",
    "    dist_sum = 0\n",
    "    for i in range(len(cluster)):\n",
    "        for j in range(i):\n",
    "            dist_sum += metric(cluster[i], cluster[j])\n",
    "    return dist_sum / ((len(cluster)-2) * (len(cluster)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def davies_bouldin_index(clusters, metric, *args):\n",
    "    centroids = [find_centroid(c, metric, *args) for c in clusters]\n",
    "    avg_dists = [avg_dist(c, metric, *args) for c in clusters]\n",
    "    n = len(clusters)\n",
    "    tab = [max([(avg_dists[i] + avg_dists[j]) / metric(centroids[i], centroids[j], *args) \\\n",
    "                for i in range(n) if i != j]) for j in range(n)]\n",
    "    return sum(tab) / n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stoplist(text, freq=0.5):\n",
    "    \"\"\"\n",
    "    Creates a stoplist from a given text.\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    for lien in text:\n",
    "        words += lien.split()\n",
    "    counter = Counter(words)\n",
    "    stoplist = {key for key, value in counter.items() if value > freq*len(text)}\n",
    "\n",
    "    result = []\n",
    "    for line in text:\n",
    "        result.append(' '.join([word for word in line.split() if word not in stoplist]))\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(file, n):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().splitlines()\n",
    "    return text[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clusters(file, clusters):\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        for c in clusters:\n",
    "            for line in c:\n",
    "                f.write(line+'\\n')\n",
    "            f.write('============\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clusters(clusters, n=10):\n",
    "    i = j =0\n",
    "    while j < n and i < len(clusters):\n",
    "        c = clusters[i]\n",
    "        if len(c) != 1:    \n",
    "            for line in c:\n",
    "                print(line)\n",
    "            print('============\\n')\n",
    "            j += 1\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(text, metric_f, eps, stop_list_frequency=None, *args):\n",
    "    working_text = text\n",
    "    if stop_list_frequency is not None:\n",
    "        working_text = create_stoplist(text, stop_list_frequency)\n",
    "        \n",
    "    def metric(x, y):\n",
    "        i, j = int(x[0]), int(y[0])\n",
    "        return metric_f(working_text[i], working_text[j])\n",
    "    \n",
    "    X = np.arange(len(working_text)).reshape(-1, 1)\n",
    "    clustering = DBSCAN(metric=metric, min_samples=1, eps=eps).fit_predict(X)\n",
    "    #print(clustering)\n",
    "    clusters = [[] for i in range(max(clustering) + 1)]\n",
    "    for i in range(len(clustering)):\n",
    "        clusters[clustering[i]].append(text[i])\n",
    "    return clusters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_text('lines.txt', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_tests(to_test, stop_list, res_v, eps_v):\n",
    "    if stop_list:\n",
    "        frequency = 0.01\n",
    "    else:\n",
    "        frequency = None\n",
    "    for i in range(len(to_test)):\n",
    "        clusters = perform_clustering(text, to_test[i], eps_v[i], frequency)\n",
    "        print(\"Funkcja: \",to_test[i].__name__)\n",
    "        print(\"Epsilon: \",eps_v[i])\n",
    "        print(\"Indeks DB: \", davies_bouldin_index(clusters, to_test[i]))\n",
    "        print(\"========\\n\")\n",
    "        if stop_list:\n",
    "            save_clusters(to_test[i].__name__ + \"_stop.txt\", clusters)\n",
    "        else:\n",
    "            save_clusters(to_test[i].__name__ + \"_no_stop.txt\", clusters)\n",
    "        res_v.append(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all(res_v, to_test):\n",
    "    for i in range(len(res_v)//2):\n",
    "        print(\"Klasteryzacja przy pomocy \" + to_test[i].__name__ + \" bez stoplisty:\\n\\n\")\n",
    "        print_clusters(res_v[i])\n",
    "        print(\"**********************************************************************\\n\\n\\n\")\n",
    "    for i in range(len(res_v)//2 ,len(res_v)):\n",
    "        print(\"Klasteryzacja przy pomocy \" + to_test[i - len(res_v)//2].__name__ + \" ze stoplistą:\\n\\n\")\n",
    "        print_clusters(res_v[i])\n",
    "        print(\"**********************************************************************\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test bez stoplisty\n",
      "\n",
      "\n",
      "Funkcja:  lcs_metric\n",
      "Epsilon:  0.3\n",
      "Indeks DB:  0.25904232112018055\n",
      "========\n",
      "\n",
      "Funkcja:  cosine_metric\n",
      "Epsilon:  0.3\n",
      "Indeks DB:  0.45212932041620785\n",
      "========\n",
      "\n",
      "Funkcja:  euclidean_metric\n",
      "Epsilon:  0.7\n",
      "Indeks DB:  0.0\n",
      "========\n",
      "\n",
      "Funkcja:  dice_metric\n",
      "Epsilon:  0.45\n",
      "Indeks DB:  0.6357253431441922\n",
      "========\n",
      "\n",
      "\n",
      "Test ze stoplistą usuwającą wyrazy częstsze niż 0.01 * liczba wyrazów\n",
      "\n",
      "\n",
      "Funkcja:  lcs_metric\n",
      "Epsilon:  0.3\n",
      "Indeks DB:  0.6210573197606084\n",
      "========\n",
      "\n",
      "Funkcja:  cosine_metric\n",
      "Epsilon:  0.3\n",
      "Indeks DB:  0.8322517512962989\n",
      "========\n",
      "\n",
      "Funkcja:  euclidean_metric\n",
      "Epsilon:  0.7\n",
      "Indeks DB:  0.65856443133609\n",
      "========\n",
      "\n",
      "Funkcja:  dice_metric\n",
      "Epsilon:  0.45\n",
      "Indeks DB:  0.7303176004602366\n",
      "========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_test = [lcs_metric, cosine_metric, euclidean_metric, dice_metric]\n",
    "res_v = []\n",
    "eps_v = [0.3, 0.3, 0.7, 0.45]\n",
    "res_vec_stop = []\n",
    "print(\"Test bez stoplisty\\n\\n\")\n",
    "perform_tests(to_test, False, res_v, eps_v)  \n",
    "print(\"\\nTest ze stoplistą usuwającą wyrazy częstsze niż 0.01 * liczba wyrazów\\n\\n\")\n",
    "perform_tests(to_test, True, res_v, eps_v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można zmienić litery na taką samą wielkość\n",
    "\n",
    "Można szukać lepszych parametrów na przykład do stworzenia stoplisty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
